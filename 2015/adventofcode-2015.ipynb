{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guided-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import functools\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "from typing import Union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-conspiracy",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "likely-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom types\n",
    "Char = str\n",
    "Dataset = list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "crazy-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'input/'\n",
    "    \n",
    "def input_for(day: int) -> Dataset:\n",
    "    try:\n",
    "        with(open(f'input/day-{day}.txt', 'r')) as file:\n",
    "            return [line.strip() for line in file ]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Input file for day {day} not found\")\n",
    "        \n",
    "\n",
    "def peek(dataset: Dataset, size: int = 5) -> Union[str, Dataset]:\n",
    "    if len(dataset) > 1:\n",
    "        return dataset[:size]\n",
    "    if len(dataset) == 1:\n",
    "        return dataset[0][:size]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def count(elements: list, predicate=bool) -> int:\n",
    "    return sum(1 for each in elements if predicate(each))\n",
    "\n",
    "def any_of(elements: list, predicate=bool) -> bool:\n",
    "    return next((True for elements in elements if predicate(elements)), False)\n",
    "\n",
    "def all_of(elements: list, predicate=bool) -> bool:\n",
    "    return not any_of(elements, lambda x: not predicate(x))\n",
    "\n",
    "log_level = 0\n",
    "def log(message: str, level: int):\n",
    "    if level <= log_level:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-liverpool",
   "metadata": {},
   "source": [
    "## Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hidden-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'()()('"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "day1 = input_for(1)[0]\n",
    "peek(day1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valid-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "def find_floor(input_values: Dataset) -> int:\n",
    "    floor = 0\n",
    "    for each in input_values:\n",
    "        if each == '(':\n",
    "            floor += 1\n",
    "        elif each == ')':\n",
    "            floor -= 1\n",
    "        else:\n",
    "            print('unknown character ' + each)\n",
    "    return floor\n",
    "\n",
    "find_floor(day1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reported-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def find_basement(input_values: Dataset) -> int:\n",
    "    floor = 0\n",
    "    for index, each in enumerate(input_values):\n",
    "        if each == '(': floor += 1\n",
    "        elif each == ')': floor -= 1\n",
    "        else: print('unknown character ' + each)\n",
    "        if floor == -1:\n",
    "            return index + 1\n",
    "\n",
    "find_basement(day1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-frank",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decimal-dayton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 3, 11], [15, 27, 5], [6, 29, 7], [30, 15, 9], [19, 29, 21]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "def parse_line(line: str) -> (int, int, int):\n",
    "    return [int(each) for each in line.split('x')]\n",
    "\n",
    "day2 = [parse_line(line) for line in input_for(2)]\n",
    "peek(day2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "structured-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606483"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "def needed_wrap_for(dimensions: (int, int, int)) -> int:\n",
    "    areas = [first * second for (first, second) in itertools.combinations(dimensions, 2)]\n",
    "    return min(areas) + 2 * sum(areas)\n",
    "\n",
    "def needed_wrap_for_all(input_dataset: list[(int, int, int)]):\n",
    "    return sum(map(needed_wrap_for, input_dataset))\n",
    "\n",
    "needed_wrap_for_all(day2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "american-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3842356"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def ribbon_length(sizes: (int, int, int)) -> int:\n",
    "    return sum(sorted(sizes)[:2]) * 2\n",
    "\n",
    "def bow_length(sizes: (int, int, int)) -> int:\n",
    "    return sizes[0] * sizes[1] * sizes[2]\n",
    "\n",
    "def ribbon_for_package(sizes: (int, int, int)) -> int:\n",
    "    return ribbon_length(sizes) + bow_length(sizes)\n",
    "\n",
    "def ribbon_for_all_packages(sizes: list[(int, int, int)]) -> int:\n",
    "    return sum(map(ribbon_for_package, sizes))\n",
    "\n",
    "ribbon_for_all_packages(day2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-architect",
   "metadata": {},
   "source": [
    "## Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "julian-breakdown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>^^v^'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "day3 = input_for(3)[0]\n",
    "peek(day3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "martial-porter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "directions = {\n",
    "    '<': (-1, 0),\n",
    "    '>': (1, 0),\n",
    "    '^': (0, 1),\n",
    "    'v': (0, -1)\n",
    "}\n",
    "\n",
    "# def visit_house(instruction):\n",
    "#\n",
    "#         if instruction == '<':\n",
    "#             x -= 1\n",
    "#         elif instruction == '>':\n",
    "#             x += 1\n",
    "#         elif instruction == '^':\n",
    "#             y += 1\n",
    "#         elif instruction == 'v':\n",
    "#             y -= 1\n",
    "#         else:\n",
    "#             print(f'unmatched character {instruction}')\n",
    "\n",
    "def visited_houses(instructions):\n",
    "    \n",
    "    position = (0, 0)\n",
    "    \n",
    "    visited = set()  # starting house\n",
    "    visited.add(position)\n",
    "\n",
    "    for instruction in instructions:\n",
    "        dx, dy = directions[instruction]\n",
    "        position = (position[0] + dx, position[1] + dy)\n",
    "        \n",
    "        visited.add(position)\n",
    "    \n",
    "    return visited\n",
    "\n",
    "len(visited_houses(day3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inclusive-championship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2360"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def parallel_visit(dataset: Dataset) -> set:\n",
    "    return visited_houses(dataset[0::2]).union(visited_houses(dataset[1::2]))\n",
    "\n",
    "len(parallel_visit(day3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-disorder",
   "metadata": {},
   "source": [
    "## Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "artificial-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "day4 = 'ckczppom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inappropriate-colors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117946"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "from hashlib import md5\n",
    "\n",
    "def hash_miner(key: str, zeros=5) -> int:\n",
    "\n",
    "    bkey = key.encode()\n",
    "    \n",
    "    def hash_for(number: int) -> str:\n",
    "        return md5(bkey + str(number).encode()).hexdigest()\n",
    "\n",
    "    match = ''.join(['0' for _ in range(zeros)])\n",
    "    \n",
    "    for current in itertools.count(0):\n",
    "        if hash_for(current)[:zeros] == match:\n",
    "            return current\n",
    "\n",
    "            \n",
    "hash_miner(day4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "final-tulsa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3938038"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "hash_miner(day4, zeros=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-victim",
   "metadata": {},
   "source": [
    "## Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tribal-breakfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zgsnvdmlfuplrubt',\n",
       " 'vlhagaovgqjmgvwq',\n",
       " 'ffumlmqwfcsyqpss',\n",
       " 'zztdcqzqddaazdjp',\n",
       " 'eavfzjajkjesnlsb']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "day5 = input_for(5)\n",
    "peek(day5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dynamic-point",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "def day5_1(dataset: Dataset):\n",
    "    rules_1 = (  # all the rules must be satisfied\n",
    "        lambda s: len(list(filter(lambda c: c in 'aeiou', s))) >= 3,\n",
    "        lambda s: re.compile(r'(.)\\1').search(s) is not None,\n",
    "        lambda s: next(filter(lambda x: x, (a == b for a, b in list(zip(s,s[1:])))), False),\n",
    "\n",
    "        lambda s: all_of(['ab', 'cd', 'pq', 'xy'], lambda x: x not in s)\n",
    "    )\n",
    "\n",
    "    def validate_string_1(input_value: str) -> bool:\n",
    "        return all_of(rules_1, lambda p: p(input_value))\n",
    "\n",
    "    return count(dataset, validate_string_1)\n",
    "\n",
    "day5_1(day5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hourly-costume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def day5_2(dataset: Dataset):\n",
    "    rules_2 = (\n",
    "        lambda s: re.compile(r'(.)(.).*\\1\\2').search(s) is not None,\n",
    "        lambda s: re.compile(r'(.).\\1').search(s) is not None\n",
    "    )\n",
    "\n",
    "    def validate_string_2(input_value: str) -> bool:\n",
    "        return all_of(rules_2, lambda p: p(input_value))\n",
    "\n",
    "    def validate_all(dataset: Dataset) -> int:\n",
    "        return count(dataset, validate_string_2)\n",
    "\n",
    "    return validate_all(dataset)\n",
    "\n",
    "day5_2(day5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-hotel",
   "metadata": {},
   "source": [
    "## Day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sized-fifteen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turn on 489,959 through 759,964',\n",
       " 'turn off 820,516 through 871,914',\n",
       " 'turn off 427,423 through 929,502',\n",
       " 'turn on 774,14 through 977,877',\n",
       " 'turn on 410,146 through 864,337']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "day6 = input_for(6)\n",
    "peek(day6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "capable-mirror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "# log_level = 0\n",
    "Point = tuple[int, int]\n",
    "\n",
    "def day6_1(instructions: Dataset) -> int:\n",
    "    \n",
    "    lights = {}\n",
    "    \n",
    "    def switch(action: str, start: Point, end: Point):\n",
    "        log(f'action {action} from {start} through {end}', 1)\n",
    "        for x in range(int(start[0]), int(end[0]) + 1):\n",
    "            for y in range(int(start[1]), int(end[1]) + 1):\n",
    "                if action == 'on':\n",
    "                    turn_on(x, y)\n",
    "                elif action == 'off':\n",
    "                    turn_off(x, y)\n",
    "                elif action == 'toggle':\n",
    "                    toggle(x, y)\n",
    "\n",
    "    def turn_on(x: int, y: int):\n",
    "        lights[x, y] = True\n",
    "\n",
    "    def turn_off(x: int, y: int):\n",
    "        if (x, y) in lights:\n",
    "            del lights[x, y]\n",
    "    \n",
    "    def toggle(x: int, y: int):\n",
    "        if (x, y) in lights:\n",
    "            turn_off(x, y)\n",
    "        else:\n",
    "            turn_on(x, y)\n",
    "    \n",
    "    \n",
    "    def parse_instruction(instruction: str):\n",
    "        tokens = instruction.split()\n",
    "        if tokens[0] == 'toggle': switch('toggle', tokens[1].split(','), tokens[3].split(','))\n",
    "        elif tokens[1] == 'on': switch('on', tokens[2].split(','), tokens[4].split(','))\n",
    "        elif tokens[1] == 'off': switch('off', tokens[2].split(','), tokens[4].split(','))\n",
    "        else: print(f'error parsing command: {instruction}')\n",
    "#         print(tokens)\n",
    "    \n",
    "    for instruction in instructions:\n",
    "        parse_instruction(instruction)\n",
    "        log(f'{len(lights)} lights are on', 1)\n",
    "        \n",
    "    return len(lights)\n",
    "\n",
    "day6_1(day6)\n",
    "# list(map(lambda line: line.split(' ')[:2], day6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unsigned-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17836115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def day6_2(instructions: Dataset) -> int:\n",
    "    \n",
    "    lights = {}\n",
    "    \n",
    "    def switch(action: str, start: Point, end: Point):\n",
    "        log(f'action {action} from {start} through {end}', 1)\n",
    "        for x in range(int(start[0]), int(end[0]) + 1):\n",
    "            for y in range(int(start[1]), int(end[1]) + 1):\n",
    "                if action == 'on':\n",
    "                    turn_on(x, y)\n",
    "                elif action == 'off':\n",
    "                    turn_off(x, y)\n",
    "                elif action == 'toggle':\n",
    "                    toggle(x, y)\n",
    "\n",
    "    def turn_on(x: int, y: int):\n",
    "        lights[x, y] = lights.get((x, y), 0) + 1\n",
    "\n",
    "    def turn_off(x: int, y: int):\n",
    "        lights[x, y] = max(0, lights.get((x, y), 0) - 1)\n",
    "\n",
    "    def toggle(x: int, y: int):\n",
    "        lights[x, y] = lights.get((x, y), 0) + 2\n",
    "    \n",
    "    \n",
    "    def parse_instruction(instruction: str):\n",
    "        tokens = instruction.split()\n",
    "        if tokens[0] == 'toggle': switch('toggle', tokens[1].split(','), tokens[3].split(','))\n",
    "        elif tokens[1] == 'on': switch('on', tokens[2].split(','), tokens[4].split(','))\n",
    "        elif tokens[1] == 'off': switch('off', tokens[2].split(','), tokens[4].split(','))\n",
    "        else: print(f'error parsing command: {instruction}')\n",
    "    \n",
    "    for instruction in instructions:\n",
    "        parse_instruction(instruction)\n",
    "        log(f'{len(lights)} lights are on', 1)\n",
    "        \n",
    "    return sum(lights.values())\n",
    "\n",
    "day6_2(day6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-spanish",
   "metadata": {},
   "source": [
    "## Day 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "shaped-strap",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lf AND lq -> ls',\n",
       " 'iu RSHIFT 1 -> jn',\n",
       " 'bo OR bu -> bv',\n",
       " 'gj RSHIFT 1 -> hc',\n",
       " 'et RSHIFT 2 -> eu']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "day7 = input_for(7)\n",
    "peek(day7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "inside-tattoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16076"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "def day7_1(dataset: Dataset, target='a', rewrite=False):\n",
    "\n",
    "    graph = {}\n",
    "    memo = {}\n",
    "\n",
    "    def var(name: str) -> callable:\n",
    "        if name not in memo:\n",
    "            memo[name] = graph[name]()\n",
    "\n",
    "        return memo[name]\n",
    "\n",
    "    def expr(expr: str) -> callable:\n",
    "        if expr.isdigit():\n",
    "            return lambda: int(expr)\n",
    "        else:\n",
    "            return lambda: var(expr)\n",
    "\n",
    "    def build_graph(instructions: Dataset):\n",
    "        for instruction in instructions:\n",
    "            parse_line(instruction)\n",
    "\n",
    "    def parse_line(instruction: str):\n",
    "        left, right = instruction.split(' -> ')\n",
    "        if not rewrite:\n",
    "            assert right not in graph  # only one definition for variable\n",
    "        graph[right] = parse_instruction(left)\n",
    "\n",
    "    def parse_instruction(instruction: str) -> callable:\n",
    "        tokens = instruction.split()\n",
    "        if len(tokens) == 1:  # 123 -> x\n",
    "            return expr(tokens[0])\n",
    "\n",
    "        if len(tokens) == 2 and tokens[0] == 'NOT':  # NOT e -> f\n",
    "            return lambda: 65_535 ^ var(tokens[1])  # negate all the 16 bits\n",
    "\n",
    "        elif len(tokens) == 3:\n",
    "            left = expr(tokens[0])\n",
    "            operator = tokens[1]\n",
    "            right = expr(tokens[2])\n",
    "            if operator == 'AND':  # x AND y -> z\n",
    "                return lambda: left() & right()\n",
    "            elif operator == 'OR':  # x OR y -> z\n",
    "                return lambda: left() | right()\n",
    "            elif operator == 'LSHIFT':  # x OR y -> z\n",
    "                return lambda: left() << right()\n",
    "            elif operator == 'RSHIFT':  # x OR y -> z\n",
    "                return lambda: left() >> right()\n",
    "\n",
    "        else:\n",
    "            print(f'error parsing instruction: {instruction}')\n",
    "\n",
    "    build_graph(dataset)\n",
    "    result = graph[target]()\n",
    "    log(memo, level=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "day7_1(day7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sharp-filing",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2797"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def day7_2(dataset: Dataset, target: str = 'a') -> int:\n",
    "    return day7_1(dataset, target=target, rewrite=True)\n",
    "\n",
    "day7_2(day7 + ['16076 -> b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-pleasure",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Day 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "diverse-customer",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"qxfcsmh\"',\n",
       " '\"ffsfyxbyuhqkpwatkjgudo\"',\n",
       " '\"byc\\\\x9dyxuafof\\\\\\\\\\\\xa6uf\\\\\\\\axfozomj\\\\\\\\olh\\\\x6a\"',\n",
       " '\"jtqvz\"',\n",
       " '\"uzezxa\\\\\"jgbmojtwyfbfguz\"']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "day8 = input_for(8)\n",
    "peek(day8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "subjective-values",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "def memory(line: str, replace_rules):\n",
    "    return functools.reduce(lambda s, rule: re.sub(rule[0], rule[1], s),\n",
    "                                replace_rules.items(), line)\n",
    "\n",
    "\n",
    "def day8_1(dataset: Dataset):\n",
    "\n",
    "    replace_rules = {  # dictionaries are now sorted in python\n",
    "        r'\\\\x[0-9a-f]{2}': 'U',\n",
    "        r'\\\\[\\\\\"]': 'E',\n",
    "        r'\"': ''\n",
    "    }\n",
    "\n",
    "    def diff(line: str) -> int:\n",
    "        encoded = memory(line, replace_rules)\n",
    "        # print(f'{line} -> {encoded} — {len(line)}, {len(encoded)}')\n",
    "        return len(line) - len(encoded)\n",
    "\n",
    "    return sum(map(diff, dataset))\n",
    "\n",
    "\n",
    "day8_1(day8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "liberal-prague",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2085"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def day8_2(dataset: Dataset) -> int:\n",
    "\n",
    "    replace_rules = {\n",
    "        r'\\\\x[0-9a-f]{2}': r'UUxUU',\n",
    "        r'\\\\[\\\\\"]': 'EEEE',\n",
    "        r'\"': r'\\\"'\n",
    "    }\n",
    "\n",
    "    def diff(line: str) -> int:\n",
    "        encoded = \"\\\"\" + memory(line, replace_rules) + \"\\\"\"\n",
    "        # print(f'{line} -> {encoded} — {len(line)}, {len(encoded)}')\n",
    "        return len(encoded) - len(line)\n",
    "\n",
    "    return sum(map(diff, dataset))\n",
    "\n",
    "\n",
    "day8_2(day8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-therapist",
   "metadata": {},
   "source": [
    "## Day 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "honey-attention",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faerun to Tristram = 65',\n",
       " 'Faerun to Tambi = 129',\n",
       " 'Faerun to Norrath = 144',\n",
       " 'Faerun to Snowdin = 71',\n",
       " 'Faerun to Straylight = 137']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "\n",
    "day9 = input_for(9)\n",
    "peek(day9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "registered-corporation",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "def day9_1(dataset: Dataset, minimize=True):\n",
    "    \n",
    "    line_matcher = re.compile(r'(\\w+)\\s+to\\s+(\\w+)\\s+=\\s+(\\d+)')\n",
    "    distances = {}\n",
    "    \n",
    "    def parse_line(line: str) -> tuple[str, str, int]:\n",
    "        return line_matcher.match(line).groups()\n",
    "    \n",
    "    def generate_distances_map(distances: list[tuple[str, str, int]]):\n",
    "        for first, second, length in distances:\n",
    "            add_distance(first, second, int(length))\n",
    "    \n",
    "    def add_distance(first: str, second: str, length: int):\n",
    "        if first not in distances:\n",
    "            distances[first] = {}\n",
    "        if second not in distances:\n",
    "            distances[second] = {}\n",
    "        distances[first][second] = length\n",
    "        distances[second][first] = length\n",
    "    \n",
    "    def route_distance(path: tuple) -> int:\n",
    "        return sum(distances[first][second] for first, second in zip(path, path[1:]))\n",
    "        \n",
    "    generate_distances_map(map(parse_line, dataset))\n",
    "\n",
    "    route_generator = map(route_distance, itertools.permutations(distances.keys()))\n",
    "    if minimize:\n",
    "        return min(route_generator)\n",
    "    else:\n",
    "        return max(route_generator)\n",
    "\n",
    "day9_1(day9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "heard-congress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def day9_2(dataset):\n",
    "    return day9_1(dataset, minimize=False)\n",
    "\n",
    "day9_2(day9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-financing",
   "metadata": {},
   "source": [
    "## Day 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "olympic-comparison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1113222113'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parsing\n",
    "day10 = '1113222113'\n",
    "day10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beginning-holiday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252594"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "\n",
    "def day10_1(seed: int, iterations=40):\n",
    "    \n",
    "    def encode(number: str) -> str:\n",
    "        count = 1\n",
    "        found = []\n",
    "        for previous, current in zip(number, number[1:]):\n",
    "            if previous != current:\n",
    "                found.append((str(count), previous))\n",
    "                count = 0\n",
    "            count += 1\n",
    "        found.append((str(count), number[-1]))\n",
    "        return ''.join(itertools.chain.from_iterable(found))\n",
    "\n",
    "    result = seed\n",
    "    for _ in range(iterations):\n",
    "        result = encode(result)\n",
    "    return len(result)\n",
    "\n",
    "day10_1(day10, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "educated-optimization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3579328"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "\n",
    "def day10_2(seed: int):\n",
    "    return day10_1(seed, 50)\n",
    "\n",
    "day10_2(day10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
