{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from __future__ import annotations\n",
    "import functools\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "from typing import Union\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# custom types\n",
    "Char = str\n",
    "Dataset = list[str]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "input_dir = 'input/'\n",
    "    \n",
    "def input_for(day: int) -> Dataset:\n",
    "    try:\n",
    "        with(open(f'input/day-{day}.txt', 'r')) as file:\n",
    "            return [line.strip() for line in file ]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Input file for day {day} not found\")\n",
    "        \n",
    "\n",
    "def peek(dataset: Dataset, size: int = 5) -> Union[str, Dataset]:\n",
    "    if len(dataset) > 1:\n",
    "        return dataset[:size]\n",
    "    if len(dataset) == 1:\n",
    "        return dataset[0][:size]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def count(elements: list, predicate=bool) -> int:\n",
    "    return sum(1 for each in elements if predicate(each))\n",
    "\n",
    "def any_of(elements: list, predicate=bool) -> bool:\n",
    "    return next((True for elements in elements if predicate(elements)), False)\n",
    "\n",
    "def all_of(elements: list, predicate=bool) -> bool:\n",
    "    return not any_of(elements, lambda x: not predicate(x))\n",
    "\n",
    "log_level = 0\n",
    "def log(message: str, level: int):\n",
    "    if level <= log_level:\n",
    "        print(message)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# input parsing\n",
    "\n",
    "day1 = input_for(1)[0]\n",
    "peek(day1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'()()('"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# part 1\n",
    "\n",
    "def find_floor(input_values: Dataset) -> int:\n",
    "    floor = 0\n",
    "    for each in input_values:\n",
    "        if each == '(':\n",
    "            floor += 1\n",
    "        elif each == ')':\n",
    "            floor -= 1\n",
    "        else:\n",
    "            print('unknown character ' + each)\n",
    "    return floor\n",
    "\n",
    "find_floor(day1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# part 2\n",
    "\n",
    "def find_basement(input_values: Dataset) -> int:\n",
    "    floor = 0\n",
    "    for index, each in enumerate(input_values):\n",
    "        if each == '(': floor += 1\n",
    "        elif each == ')': floor -= 1\n",
    "        else: print('unknown character ' + each)\n",
    "        if floor == -1:\n",
    "            return index + 1\n",
    "\n",
    "find_basement(day1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# input parsing\n",
    "\n",
    "def parse_line(line: str) -> (int, int, int):\n",
    "    return [int(each) for each in line.split('x')]\n",
    "\n",
    "day2 = [parse_line(line) for line in input_for(2)]\n",
    "peek(day2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[20, 3, 11], [15, 27, 5], [6, 29, 7], [30, 15, 9], [19, 29, 21]]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# part 1\n",
    "\n",
    "def needed_wrap_for(dimensions: tuple[int, int, int]) -> int:\n",
    "    areas = [first * second for (first, second) in itertools.combinations(dimensions, 2)]\n",
    "    return min(areas) + 2 * sum(areas)\n",
    "\n",
    "def needed_wrap_for_all(input_dataset: list[(int, int, int)]):\n",
    "    return sum(map(needed_wrap_for, input_dataset))\n",
    "\n",
    "needed_wrap_for_all(day2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1606483"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# part 2\n",
    "\n",
    "def ribbon_length(sizes: tuple[int, int, int]) -> int:\n",
    "    return sum(sorted(sizes)[:2]) * 2\n",
    "\n",
    "def bow_length(sizes: tuple[int, int, int]) -> int:\n",
    "    return sizes[0] * sizes[1] * sizes[2]\n",
    "\n",
    "def ribbon_for_package(sizes: tuple[int, int, int]) -> int:\n",
    "    return ribbon_length(sizes) + bow_length(sizes)\n",
    "\n",
    "def ribbon_for_all_packages(sizes: list[tuple[int, int, int]]) -> int:\n",
    "    return sum(map(ribbon_for_package, sizes))\n",
    "\n",
    "ribbon_for_all_packages(day2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3842356"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# input parsing\n",
    "\n",
    "day3 = input_for(3)[0]\n",
    "peek(day3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'>^^v^'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# part 1\n",
    "\n",
    "directions = {\n",
    "    '<': (-1, 0),\n",
    "    '>': (1, 0),\n",
    "    '^': (0, 1),\n",
    "    'v': (0, -1)\n",
    "}\n",
    "\n",
    "# def visit_house(instruction):\n",
    "#\n",
    "#         if instruction == '<':\n",
    "#             x -= 1\n",
    "#         elif instruction == '>':\n",
    "#             x += 1\n",
    "#         elif instruction == '^':\n",
    "#             y += 1\n",
    "#         elif instruction == 'v':\n",
    "#             y -= 1\n",
    "#         else:\n",
    "#             print(f'unmatched character {instruction}')\n",
    "\n",
    "def visited_houses(instructions):\n",
    "    \n",
    "    position = (0, 0)\n",
    "    \n",
    "    visited = set()  # starting house\n",
    "    visited.add(position)\n",
    "\n",
    "    for instruction in instructions:\n",
    "        dx, dy = directions[instruction]\n",
    "        position = (position[0] + dx, position[1] + dy)\n",
    "        \n",
    "        visited.add(position)\n",
    "    \n",
    "    return visited\n",
    "\n",
    "len(visited_houses(day3))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2592"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# part 2\n",
    "\n",
    "def parallel_visit(dataset: Dataset) -> set:\n",
    "    return visited_houses(dataset[0::2]).union(visited_houses(dataset[1::2]))\n",
    "\n",
    "len(parallel_visit(day3))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2360"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "day4 = 'ckczppom'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# part 1\n",
    "\n",
    "from hashlib import md5\n",
    "\n",
    "def hash_miner(key: str, zeros=5) -> int:\n",
    "\n",
    "    bkey = key.encode()\n",
    "    \n",
    "    def hash_for(number: int) -> str:\n",
    "        return md5(bkey + str(number).encode()).hexdigest()\n",
    "\n",
    "    match = ''.join(['0' for _ in range(zeros)])\n",
    "    \n",
    "    for current in itertools.count(0):\n",
    "        if hash_for(current)[:zeros] == match:\n",
    "            return current\n",
    "\n",
    "            \n",
    "hash_miner(day4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "117946"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# part 2\n",
    "\n",
    "hash_miner(day4, zeros=6)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3938038"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# input parsing\n",
    "\n",
    "day5 = input_for(5)\n",
    "peek(day5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['zgsnvdmlfuplrubt',\n",
       " 'vlhagaovgqjmgvwq',\n",
       " 'ffumlmqwfcsyqpss',\n",
       " 'zztdcqzqddaazdjp',\n",
       " 'eavfzjajkjesnlsb']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# part 1\n",
    "\n",
    "def day5_1(dataset: Dataset):\n",
    "    rules_1 = (  # all the rules must be satisfied\n",
    "        lambda s: len(list(filter(lambda c: c in 'aeiou', s))) >= 3,\n",
    "        lambda s: re.compile(r'(.)\\1').search(s) is not None,\n",
    "        lambda s: next(filter(lambda x: x, (a == b for a, b in list(zip(s,s[1:])))), False),\n",
    "\n",
    "        lambda s: all_of(['ab', 'cd', 'pq', 'xy'], lambda x: x not in s)\n",
    "    )\n",
    "\n",
    "    def validate_string_1(input_value: str) -> bool:\n",
    "        return all_of(rules_1, lambda p: p(input_value))\n",
    "\n",
    "    return count(dataset, validate_string_1)\n",
    "\n",
    "day5_1(day5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# part 2\n",
    "\n",
    "def day5_2(dataset: Dataset):\n",
    "    rules_2 = (\n",
    "        lambda s: re.compile(r'(.)(.).*\\1\\2').search(s) is not None,\n",
    "        lambda s: re.compile(r'(.).\\1').search(s) is not None\n",
    "    )\n",
    "\n",
    "    def validate_string_2(input_value: str) -> bool:\n",
    "        return all_of(rules_2, lambda p: p(input_value))\n",
    "\n",
    "    def validate_all(dataset: Dataset) -> int:\n",
    "        return count(dataset, validate_string_2)\n",
    "\n",
    "    return validate_all(dataset)\n",
    "\n",
    "day5_2(day5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 6"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# input parsing\n",
    "\n",
    "day6 = input_for(6)\n",
    "peek(day6)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['turn on 489,959 through 759,964',\n",
       " 'turn off 820,516 through 871,914',\n",
       " 'turn off 427,423 through 929,502',\n",
       " 'turn on 774,14 through 977,877',\n",
       " 'turn on 410,146 through 864,337']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# part 1\n",
    "\n",
    "# log_level = 0\n",
    "Point = tuple[int, int]\n",
    "\n",
    "def day6_1(instructions: Dataset) -> int:\n",
    "    \n",
    "    lights = {}\n",
    "    \n",
    "    def switch(action: str, start: Point, end: Point):\n",
    "        log(f'action {action} from {start} through {end}', 1)\n",
    "        for x in range(int(start[0]), int(end[0]) + 1):\n",
    "            for y in range(int(start[1]), int(end[1]) + 1):\n",
    "                if action == 'on':\n",
    "                    turn_on(x, y)\n",
    "                elif action == 'off':\n",
    "                    turn_off(x, y)\n",
    "                elif action == 'toggle':\n",
    "                    toggle(x, y)\n",
    "\n",
    "    def turn_on(x: int, y: int):\n",
    "        lights[x, y] = True\n",
    "\n",
    "    def turn_off(x: int, y: int):\n",
    "        if (x, y) in lights:\n",
    "            del lights[x, y]\n",
    "    \n",
    "    def toggle(x: int, y: int):\n",
    "        if (x, y) in lights:\n",
    "            turn_off(x, y)\n",
    "        else:\n",
    "            turn_on(x, y)\n",
    "    \n",
    "    \n",
    "    def parse_instruction(instruction: str):\n",
    "        tokens = instruction.split()\n",
    "        if tokens[0] == 'toggle': switch('toggle', tokens[1].split(','), tokens[3].split(','))\n",
    "        elif tokens[1] == 'on': switch('on', tokens[2].split(','), tokens[4].split(','))\n",
    "        elif tokens[1] == 'off': switch('off', tokens[2].split(','), tokens[4].split(','))\n",
    "        else: print(f'error parsing command: {instruction}')\n",
    "#         print(tokens)\n",
    "    \n",
    "    for instruction in instructions:\n",
    "        parse_instruction(instruction)\n",
    "        log(f'{len(lights)} lights are on', 1)\n",
    "        \n",
    "    return len(lights)\n",
    "\n",
    "day6_1(day6)\n",
    "# list(map(lambda line: line.split(' ')[:2], day6))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "569999"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# part 2\n",
    "\n",
    "def day6_2(instructions: Dataset) -> int:\n",
    "    \n",
    "    lights = {}\n",
    "    \n",
    "    def switch(action: str, start: Point, end: Point):\n",
    "        log(f'action {action} from {start} through {end}', 1)\n",
    "        for x in range(int(start[0]), int(end[0]) + 1):\n",
    "            for y in range(int(start[1]), int(end[1]) + 1):\n",
    "                if action == 'on':\n",
    "                    turn_on(x, y)\n",
    "                elif action == 'off':\n",
    "                    turn_off(x, y)\n",
    "                elif action == 'toggle':\n",
    "                    toggle(x, y)\n",
    "\n",
    "    def turn_on(x: int, y: int):\n",
    "        lights[x, y] = lights.get((x, y), 0) + 1\n",
    "\n",
    "    def turn_off(x: int, y: int):\n",
    "        lights[x, y] = max(0, lights.get((x, y), 0) - 1)\n",
    "\n",
    "    def toggle(x: int, y: int):\n",
    "        lights[x, y] = lights.get((x, y), 0) + 2\n",
    "    \n",
    "    \n",
    "    def parse_instruction(instruction: str):\n",
    "        tokens = instruction.split()\n",
    "        if tokens[0] == 'toggle': switch('toggle', tokens[1].split(','), tokens[3].split(','))\n",
    "        elif tokens[1] == 'on': switch('on', tokens[2].split(','), tokens[4].split(','))\n",
    "        elif tokens[1] == 'off': switch('off', tokens[2].split(','), tokens[4].split(','))\n",
    "        else: print(f'error parsing command: {instruction}')\n",
    "    \n",
    "    for instruction in instructions:\n",
    "        parse_instruction(instruction)\n",
    "        log(f'{len(lights)} lights are on', 1)\n",
    "        \n",
    "    return sum(lights.values())\n",
    "\n",
    "day6_2(day6)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17836115"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 7"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# input parsing\n",
    "\n",
    "day7 = input_for(7)\n",
    "peek(day7)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['lf AND lq -> ls',\n",
       " 'iu RSHIFT 1 -> jn',\n",
       " 'bo OR bu -> bv',\n",
       " 'gj RSHIFT 1 -> hc',\n",
       " 'et RSHIFT 2 -> eu']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# part 1\n",
    "\n",
    "def day7_1(dataset: Dataset, target='a', rewrite=False):\n",
    "\n",
    "    graph = {}\n",
    "    memo = {}\n",
    "\n",
    "    def var(name: str) -> callable:\n",
    "        if name not in memo:\n",
    "            memo[name] = graph[name]()\n",
    "\n",
    "        return memo[name]\n",
    "\n",
    "    def expr(expr: str) -> callable:\n",
    "        if expr.isdigit():\n",
    "            return lambda: int(expr)\n",
    "        else:\n",
    "            return lambda: var(expr)\n",
    "\n",
    "    def build_graph(instructions: Dataset):\n",
    "        for instruction in instructions:\n",
    "            parse_line(instruction)\n",
    "\n",
    "    def parse_line(instruction: str):\n",
    "        left, right = instruction.split(' -> ')\n",
    "        if not rewrite:\n",
    "            assert right not in graph  # only one definition for variable\n",
    "        graph[right] = parse_instruction(left)\n",
    "\n",
    "    def parse_instruction(instruction: str) -> callable:\n",
    "        tokens = instruction.split()\n",
    "        if len(tokens) == 1:  # 123 -> x\n",
    "            return expr(tokens[0])\n",
    "\n",
    "        if len(tokens) == 2 and tokens[0] == 'NOT':  # NOT e -> f\n",
    "            return lambda: 65_535 ^ var(tokens[1])  # negate all the 16 bits\n",
    "\n",
    "        elif len(tokens) == 3:\n",
    "            left = expr(tokens[0])\n",
    "            operator = tokens[1]\n",
    "            right = expr(tokens[2])\n",
    "            if operator == 'AND':  # x AND y -> z\n",
    "                return lambda: left() & right()\n",
    "            elif operator == 'OR':  # x OR y -> z\n",
    "                return lambda: left() | right()\n",
    "            elif operator == 'LSHIFT':  # x OR y -> z\n",
    "                return lambda: left() << right()\n",
    "            elif operator == 'RSHIFT':  # x OR y -> z\n",
    "                return lambda: left() >> right()\n",
    "\n",
    "        else:\n",
    "            print(f'error parsing instruction: {instruction}')\n",
    "\n",
    "    build_graph(dataset)\n",
    "    result = graph[target]()\n",
    "    log(memo, level=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "day7_1(day7)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16076"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# part 2\n",
    "\n",
    "def day7_2(dataset: Dataset, target: str = 'a') -> int:\n",
    "    return day7_1(dataset, target=target, rewrite=True)\n",
    "\n",
    "day7_2(day7 + ['16076 -> b'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2797"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 8"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# input parsing\n",
    "\n",
    "day8 = input_for(8)\n",
    "peek(day8)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['\"qxfcsmh\"',\n",
       " '\"ffsfyxbyuhqkpwatkjgudo\"',\n",
       " '\"byc\\\\x9dyxuafof\\\\\\\\\\\\xa6uf\\\\\\\\axfozomj\\\\\\\\olh\\\\x6a\"',\n",
       " '\"jtqvz\"',\n",
       " '\"uzezxa\\\\\"jgbmojtwyfbfguz\"']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# part 1\n",
    "def memory(line: str, replace_rules):\n",
    "    return functools.reduce(lambda s, rule: re.sub(rule[0], rule[1], s),\n",
    "                                replace_rules.items(), line)\n",
    "\n",
    "\n",
    "def day8_1(dataset: Dataset):\n",
    "\n",
    "    replace_rules = {  # dictionaries are now sorted in python\n",
    "        r'\\\\x[0-9a-f]{2}': 'U',\n",
    "        r'\\\\[\\\\\"]': 'E',\n",
    "        r'\"': ''\n",
    "    }\n",
    "\n",
    "    def diff(line: str) -> int:\n",
    "        encoded = memory(line, replace_rules)\n",
    "        # print(f'{line} -> {encoded} — {len(line)}, {len(encoded)}')\n",
    "        return len(line) - len(encoded)\n",
    "\n",
    "    return sum(map(diff, dataset))\n",
    "\n",
    "\n",
    "day8_1(day8)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1350"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def day8_2(dataset: Dataset) -> int:\n",
    "\n",
    "    replace_rules = {\n",
    "        r'\\\\x[0-9a-f]{2}': r'UUxUU',\n",
    "        r'\\\\[\\\\\"]': 'EEEE',\n",
    "        r'\"': r'\\\"'\n",
    "    }\n",
    "\n",
    "    def diff(line: str) -> int:\n",
    "        encoded = \"\\\"\" + memory(line, replace_rules) + \"\\\"\"\n",
    "        # print(f'{line} -> {encoded} — {len(line)}, {len(encoded)}')\n",
    "        return len(encoded) - len(line)\n",
    "\n",
    "    return sum(map(diff, dataset))\n",
    "\n",
    "\n",
    "day8_2(day8)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2085"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 9"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# input parsing\n",
    "\n",
    "day9 = input_for(9)\n",
    "peek(day9)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Faerun to Tristram = 65',\n",
       " 'Faerun to Tambi = 129',\n",
       " 'Faerun to Norrath = 144',\n",
       " 'Faerun to Snowdin = 71',\n",
       " 'Faerun to Straylight = 137']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# part 1\n",
    "\n",
    "def day9_1(dataset: Dataset, minimize=True):\n",
    "    \n",
    "    line_matcher = re.compile(r'(\\w+)\\s+to\\s+(\\w+)\\s+=\\s+(\\d+)')\n",
    "    distances = {}\n",
    "    \n",
    "    def parse_line(line: str) -> tuple[str, str, int]:\n",
    "        return line_matcher.match(line).groups()\n",
    "    \n",
    "    def generate_distances_map(distances: list[tuple[str, str, int]]):\n",
    "        for first, second, length in distances:\n",
    "            add_distance(first, second, int(length))\n",
    "    \n",
    "    def add_distance(first: str, second: str, length: int):\n",
    "        if first not in distances:\n",
    "            distances[first] = {}\n",
    "        if second not in distances:\n",
    "            distances[second] = {}\n",
    "        distances[first][second] = length\n",
    "        distances[second][first] = length\n",
    "    \n",
    "    def route_distance(path: tuple) -> int:\n",
    "        return sum(distances[first][second] for first, second in zip(path, path[1:]))\n",
    "        \n",
    "    generate_distances_map(map(parse_line, dataset))\n",
    "\n",
    "    route_generator = map(route_distance, itertools.permutations(distances.keys()))\n",
    "    if minimize:\n",
    "        return min(route_generator)\n",
    "    else:\n",
    "        return max(route_generator)\n",
    "\n",
    "day9_1(day9)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# part 2\n",
    "\n",
    "def day9_2(dataset):\n",
    "    return day9_1(dataset, minimize=False)\n",
    "\n",
    "day9_2(day9)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# input parsing\n",
    "day10 = '1113222113'\n",
    "day10"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1113222113'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# part 1\n",
    "\n",
    "def day10_1(seed: int, iterations=40):\n",
    "    \n",
    "    def encode(number: str) -> str:\n",
    "        count = 1\n",
    "        found = []\n",
    "        for previous, current in zip(number, number[1:]):\n",
    "            if previous != current:\n",
    "                found.append((str(count), previous))\n",
    "                count = 0\n",
    "            count += 1\n",
    "        found.append((str(count), number[-1]))\n",
    "        return ''.join(itertools.chain.from_iterable(found))\n",
    "\n",
    "    result = seed\n",
    "    for _ in range(iterations):\n",
    "        result = encode(result)\n",
    "    return len(result)\n",
    "\n",
    "day10_1(day10, 40)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "252594"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# part 2\n",
    "\n",
    "def day10_2(seed: int):\n",
    "    return day10_1(seed, 50)\n",
    "\n",
    "day10_2(day10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3579328"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 11"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# input parsing\n",
    "day11 = 'hxbxwxba'\n",
    "day11"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hxbxwxba'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# part 1\n",
    "\n",
    "def day11_1(seed: Dataset):\n",
    "    current = list(map(ord, reversed(seed)))\n",
    "    min_char = ord('a')\n",
    "    max_char = ord('z')\n",
    "    \n",
    "    banned_chars = list(map(ord, ('i', 'j', 'o')))\n",
    "\n",
    "    double_matcher = re.compile(r'(.)\\1.*(.)\\2')\n",
    "    \n",
    "    def check_consecutive_chars(sequence: list[int]) -> bool:\n",
    "        for i, _ in enumerate(sequence[:-2]):\n",
    "            if sequence[i] == (sequence[i+1] + 1) == sequence[i+2] + 2:\n",
    "                return True\n",
    "        return False        \n",
    "    \n",
    "    rules = [\n",
    "        lambda p: re.search(double_matcher, ''.join(map(chr, p))),\n",
    "        lambda p: all_of(p, lambda c: c not in banned_chars),\n",
    "        check_consecutive_chars\n",
    "    ]\n",
    "    \n",
    "    def is_valid(password: str) -> bool:\n",
    "        return all_of(rules, lambda rule: rule(password))\n",
    "    \n",
    "    def next_char(index=0):\n",
    "        current[index] += 1\n",
    "        \n",
    "        if current[index] > max_char:\n",
    "            current[index] = min_char\n",
    "            next_char(index + 1)\n",
    "    \n",
    "    while True:\n",
    "        next_char()\n",
    "        if is_valid(current):\n",
    "            return ''.join(map(chr, reversed(current)))\n",
    "\n",
    "day11_1(day11)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hxbxxyzz'"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# part 2\n",
    "\n",
    "def day11_2(seed: Dataset):\n",
    "    return day11_1(day11_1(seed))\n",
    "day11_2(day11)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hxcaabcc'"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Day 12"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# input parsing\n",
    "\n",
    "day12 = input_for(12)\n",
    "peek(day12)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[[\"gr'"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# part 1\n",
    "# import json\n",
    "\n",
    "# json.loads(day12[0])\n",
    "\n",
    "def day12_1(dataset: Dataset):\n",
    "    number_matcher = re.compile(r'-?\\d+')\n",
    "    return sum(map(int, number_matcher.findall(dataset)))\n",
    "    \n",
    "\n",
    "day12_1(day12[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "191164"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# part 2\n",
    "\n",
    "def day12_2(dataset: Dataset):\n",
    "    import json\n",
    "    \n",
    "    json_document = json.loads(dataset)\n",
    "\n",
    "    def count_values(document):\n",
    "        if isinstance(document, int):\n",
    "            return document\n",
    "        \n",
    "        elif isinstance(document, list):\n",
    "            return sum([count_values(each) for each in document])\n",
    "        \n",
    "        elif isinstance(document, dict):\n",
    "            if 'red' in document.values():\n",
    "                return 0\n",
    "            return sum([count_values(value) for _, value in document.items()])\n",
    "\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    return count_values(json_document)\n",
    "\n",
    "\n",
    "day12_2(day12[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "87842"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# input parsing\n",
    "\n",
    "day13 = input_for(13)\n",
    "peek(day13)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Alice would lose 57 happiness units by sitting next to Bob.',\n",
       " 'Alice would lose 62 happiness units by sitting next to Carol.',\n",
       " 'Alice would lose 75 happiness units by sitting next to David.',\n",
       " 'Alice would gain 71 happiness units by sitting next to Eric.',\n",
       " 'Alice would lose 22 happiness units by sitting next to Frank.']"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# part 1\n",
    "\n",
    "def day13_1(dataset: Dataset, with_me=False):\n",
    "    def parse_line(line):\n",
    "        tokens = line.split()\n",
    "        if tokens[2] == 'lose':\n",
    "            coefficient = -1\n",
    "        elif tokens[2] == 'gain':\n",
    "            coefficient = 1\n",
    "        else:\n",
    "            print(\"error reading input\")\n",
    "        \n",
    "        return (tokens[0], tokens[-1].strip('.'), int(tokens[3]) * coefficient)\n",
    "    \n",
    "    lines = list(map(parse_line, dataset))\n",
    "\n",
    "    scores = {(first, second): score for first, second, score in lines}\n",
    "\n",
    "    def score_for_couple(couple):\n",
    "        return scores.get(couple, 0)\n",
    "\n",
    "    def calculate_score(permutation):\n",
    "        score_right = sum(score_for_couple(couple) for couple in zip(permutation, permutation[1:] + (permutation[0],)))\n",
    "        score_left = sum(score_for_couple(couple) for couple in zip(permutation, (permutation[-1],) + permutation[:-1]))\n",
    "        return score_left + score_right\n",
    "\n",
    "    guests = set([line[0] for line in lines])\n",
    "    if with_me:\n",
    "        guests.add('__me__')\n",
    "\n",
    "    return max(calculate_score(permutation) for permutation in itertools.permutations(guests))\n",
    "\n",
    "day13_1(day13)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# part 2\n",
    "def day13_2(dataset):\n",
    "    return day13_1(dataset, with_me=True)\n",
    "\n",
    "day13_2(day13)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "91d6d7a7bbec36cb068d788f38682d797ed16825aa3b286bac4fcaa8299b2ac2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}